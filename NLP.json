{"cells":[{"cell_type":"markdown","id":"43da86cb","metadata":{"id":"43da86cb"},"source":["#NATURAL LANGUAGE PROCESSING (NLP)"]},{"cell_type":"markdown","id":"a6b0e3d7","metadata":{"id":"a6b0e3d7"},"source":["## Importing Libraries"]},{"cell_type":"code","execution_count":null,"id":"3247e4ca","metadata":{"id":"3247e4ca"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n","# sns.set()"]},{"cell_type":"code","execution_count":null,"id":"96e22325","metadata":{"id":"96e22325"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"0d39699a","metadata":{"id":"0d39699a"},"source":["=========="]},{"cell_type":"markdown","id":"f8c2ed4b","metadata":{"id":"f8c2ed4b"},"source":["## Spam Detection | Text Classification"]},{"cell_type":"markdown","id":"65d6f76f","metadata":{"id":"65d6f76f"},"source":["Dataset Source: https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset"]},{"cell_type":"code","execution_count":null,"id":"57702ea2","metadata":{"id":"57702ea2"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"a2b9ccf5","metadata":{"id":"a2b9ccf5"},"source":["## Importing & Inspecting Data"]},{"cell_type":"code","execution_count":null,"id":"fcf4c571","metadata":{"id":"fcf4c571"},"outputs":[],"source":["sms = pd.read_csv('datasets/spam.csv', encoding='ISO-8859-1')\n","sms.head()"]},{"cell_type":"code","execution_count":null,"id":"9fa39d96","metadata":{"id":"9fa39d96"},"outputs":[],"source":["sms.info()"]},{"cell_type":"code","execution_count":null,"id":"191855a5","metadata":{"id":"191855a5"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"dc5f59f4","metadata":{"id":"dc5f59f4"},"source":["## Pre-processing Data"]},{"cell_type":"markdown","id":"f771b00b","metadata":{"id":"f771b00b"},"source":["##### Basic Data Pre-processing"]},{"cell_type":"code","execution_count":null,"id":"6af786dd","metadata":{"id":"6af786dd"},"outputs":[],"source":["sms = sms.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)"]},{"cell_type":"code","execution_count":null,"id":"0d5d8c22","metadata":{"id":"0d5d8c22"},"outputs":[],"source":["sms.columns = ['labels', 'data']"]},{"cell_type":"code","execution_count":null,"id":"884d08ad","metadata":{"id":"884d08ad"},"outputs":[],"source":["sms.head()"]},{"cell_type":"code","execution_count":null,"id":"c88e031e","metadata":{"id":"c88e031e"},"outputs":[],"source":["X = sms['data']\n","X"]},{"cell_type":"code","execution_count":null,"id":"e9ec1ec4","metadata":{"id":"e9ec1ec4"},"outputs":[],"source":["y = sms['labels'].map({'ham': 0, 'spam': 1}).values\n","y"]},{"cell_type":"code","execution_count":null,"id":"bb16e6df","metadata":{"id":"bb16e6df"},"outputs":[],"source":["sms.head()"]},{"cell_type":"code","execution_count":null,"id":"9ce4f364","metadata":{"id":"9ce4f364"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"]},{"cell_type":"code","execution_count":null,"id":"00b469c9","metadata":{"id":"00b469c9"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"e14982bf","metadata":{"id":"e14982bf"},"source":["##### Text Pre-processing"]},{"cell_type":"code","execution_count":null,"id":"a5c5f48a","metadata":{"scrolled":true,"id":"a5c5f48a"},"outputs":[],"source":["from tensorflow.keras.preprocessing.text import Tokenizer"]},{"cell_type":"code","execution_count":null,"id":"e34a2962","metadata":{"id":"e34a2962"},"outputs":[],"source":["tokenizer = Tokenizer(num_words=20000)"]},{"cell_type":"code","execution_count":null,"id":"3192c6e7","metadata":{"id":"3192c6e7"},"outputs":[],"source":["tokenizer.fit_on_texts(X_train)"]},{"cell_type":"code","execution_count":null,"id":"42cf5016","metadata":{"id":"42cf5016"},"outputs":[],"source":["seq_train = tokenizer.texts_to_sequences(X_train)"]},{"cell_type":"code","execution_count":null,"id":"07e7ffa4","metadata":{"id":"07e7ffa4"},"outputs":[],"source":["seq_test = tokenizer.texts_to_sequences(X_test)"]},{"cell_type":"code","execution_count":null,"id":"2ef26cc0","metadata":{"id":"2ef26cc0"},"outputs":[],"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences"]},{"cell_type":"code","execution_count":null,"id":"aa9b37e9","metadata":{"id":"aa9b37e9"},"outputs":[],"source":["data_train = pad_sequences(seq_train)\n","data_train"]},{"cell_type":"code","execution_count":null,"id":"476e40d5","metadata":{"id":"476e40d5"},"outputs":[],"source":["data_train.shape"]},{"cell_type":"code","execution_count":null,"id":"6764382a","metadata":{"id":"6764382a"},"outputs":[],"source":["data_test = pad_sequences(seq_test, maxlen=data_train.shape[1])\n","data_test"]},{"cell_type":"code","execution_count":null,"id":"98045131","metadata":{"id":"98045131"},"outputs":[],"source":["data_test.shape"]},{"cell_type":"code","execution_count":null,"id":"188a077b","metadata":{"id":"188a077b"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"d4fce451","metadata":{"id":"d4fce451"},"source":["## Exploring Data"]},{"cell_type":"code","execution_count":null,"id":"99980076","metadata":{"scrolled":true,"id":"99980076"},"outputs":[],"source":["plt.title('%age of samples in each class')\n","plt.pie(sms['labels'].value_counts(),labels=['ham','spam'],colors=sns.color_palette('pastel'),explode=[0,0.1],autopct='%.2f%%')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"6ad03dd4","metadata":{"id":"6ad03dd4"},"outputs":[],"source":["sns.countplot(x=sms['labels'])"]},{"cell_type":"code","execution_count":null,"id":"0e60b99e","metadata":{"id":"0e60b99e"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"4eca46d4","metadata":{"id":"4eca46d4"},"source":["## Model Training & Building"]},{"cell_type":"code","execution_count":null,"id":"2f16b441","metadata":{"id":"2f16b441"},"outputs":[],"source":["from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D\n","from tensorflow.keras.layers import LSTM, Embedding\n","from tensorflow.keras.models import Model"]},{"cell_type":"code","execution_count":null,"id":"1ca8debc","metadata":{"id":"1ca8debc"},"outputs":[],"source":["# Input layer\n","i = Input(shape=(data_train.shape[1],))  # input layer takes in sequences of integers\n","\n","# Embedding layer\n","x = Embedding(len(tokenizer.word_index) + 1, 20)(i) # This takes in sequences of integers and returns sequences of word vectors\n","\n","# LSTM layer\n","x = LSTM(15, return_sequences=True)(x)\n","x = GlobalMaxPooling1D()(x)\n","\n","# Dense layer\n","x = Dense(1, activation='sigmoid')(x)\n","# it is an binary classification problem, so we are using activation function ='sigmoid'\n","\n","model = Model(i, x)"]},{"cell_type":"code","execution_count":null,"id":"b60568fa","metadata":{"id":"b60568fa"},"outputs":[],"source":["'''\n","model=Sequential()\n","\n","# embedding layer\n","model.add(Embedding(max_words,50,input_length=max_len,trainable=True))\n","\n","# lstm layer\n","model.add(LSTM(100,return_sequences=True,dropout=0.5))\n","model.add(Flatten())\n","\n","# Dense layer\n","model.add(Dense(200,activation='relu',name='hl1')) # hidden layer 1\n","model.add(Dense(100,activation='relu',name='hl2')) # hidden layer 2\n","model.add(Dense(1,activation='sigmoid',name='ol')) # output layer\n","'''"]},{"cell_type":"code","execution_count":null,"id":"1a435956","metadata":{"id":"1a435956"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"5fca0ffc","metadata":{"id":"5fca0ffc"},"outputs":[],"source":["model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"id":"f26532c6","metadata":{"id":"f26532c6"},"outputs":[],"source":["hist = model.fit(x=data_train, y=y_train, epochs=20, validation_data=(data_test, y_test))"]},{"cell_type":"code","execution_count":null,"id":"dda3594e","metadata":{"id":"dda3594e"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"a0111e0c","metadata":{"id":"a0111e0c"},"source":["## Model Evaluation"]},{"cell_type":"code","execution_count":null,"id":"f25c207e","metadata":{"id":"f25c207e"},"outputs":[],"source":["plt.plot(hist.history['loss'], label='Loss')\n","plt.plot(hist.history['val_loss'], label='Validation Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"3f95522a","metadata":{"scrolled":true,"id":"3f95522a"},"outputs":[],"source":["plt.plot(hist.history['accuracy'], label='Accuracy')\n","plt.plot(hist.history['val_accuracy'], label='Validation accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"aea3c923","metadata":{"id":"aea3c923"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}